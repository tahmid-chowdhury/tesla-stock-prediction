bidirectional: False
lstm_units_1: 128
return_sequences: False
dropout_1: 0.1
lstm_units_2: 16
dropout_2: 0.4
use_dense_layer: False
dense_units: 56
dense_activation: relu
use_second_dropout: True
learning_rate: 0.003
optimizer: adam
dropout_3: 0.4
tuner/epochs: 4
tuner/initial_epoch: 0
tuner/bracket: 3
tuner/round: 0
