bidirectional: False
lstm_units_1: 96
return_sequences: False
dropout_1: 0.0
lstm_units_2: 16
dropout_2: 0.1
use_dense_layer: True
dense_units: 56
dense_activation: selu
use_second_dropout: True
learning_rate: 0.001
optimizer: adam
dropout_3: 0.2
tuner/epochs: 34
tuner/initial_epoch: 0
tuner/bracket: 1
tuner/round: 0
